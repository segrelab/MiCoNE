# Pipelines for the network_inference module

## Bootstrap

[network_inference.bootstrap.resample]
  env = "mindpipe-sparcc"
  root_dir = "network_inference/bootstrap/resample"
  [[network_inference.bootstrap.resample.input]]
    datatype = "otu_table"
    format = ["tsv"]
  [[network_inference.bootstrap.resample.parameters]]
    process = "resample"
    bootstraps = 1000
    ncpus = 1
  [[network_inference.bootstrap.resample.output]]
    datatype = "otu_bootstrap"
    format = ["boot"]
    location = "**/*.boot"

[network_inference.bootstrap.pvalue]
  env = "mindpipe-sparcc"
  root_dir = "network_inference/bootstrap/pvalue"
  [[network_inference.bootstrap.pvalue.input]]
    datatype = "otu_table"
    format = ["tsv"]
  [[network_inference.bootstrap.pvalue.input]]
    datatype = "interaction_table"
    format = ["tsv"]
  [[network_inference.bootstrap.pvalue.input]]
    datatype = "interaction_bootstrap"
    format = ["boot"]
  [[network_inference.bootstrap.pvalue.parameters]]
    process = "calculate_pvalues"
    ncpus = 1
  [[network_inference.bootstrap.pvalue.output]]
    datatype = "pvalue_table"
    format = ["tsv"]
    location = "**/*_pval.tsv"


## Correlation

[network_inference.correlation.sparcc]
  env = "mindpipe-sparcc"
  root_dir = "network_inference/sparcc"
  [[network_inference.correlation.sparcc.input]]
    datatype = "otu_table"
    format = ["tsv"]
  [[network_inference.correlation.sparcc.input]]
    datatype = "otu_bootstrap"
    format = ["boot"]
  [[network_inference.correlation.sparcc.parameters]]
    process = "sparcc"
    iterations = 50
    ncpus = 1
  [[network_inference.correlation.sparcc.output]]
    datatype = "interaction_table"
    format = ["tsv"]
    location = "**/*_corr.tsv"
  [[network_inference.correlation.sparcc.output]]
    datatype = "interaction_bootstrap"
    format = ["boot"]
    location = "**/*_corr.boot"

[network_inference.correlation.pearson]
  root_dir = "network_inference/pearson"
  [[network_inference.correlation.pearson.input]]
    datatype = "otu_table"
    format = ["tsv"]
  [[network_inference.correlation.pearson.input]]
    datatype = "otu_bootstrap"
    format = ["boot"]
  [[network_inference.correlation.pearson.parameters]]
    process = "pearson"
  [[network_inference.correlation.pearson.output]]
    datatype = "interaction_table"
    format = ["tsv"]
    location = "**/*_corr.tsv"
  [[network_inference.correlation.pearson.output]]
    datatype = "interaction_bootstrap"
    format = ["boot"]
    location = "**/*_corr.boot"

[network_inference.correlation.spearman]
  root_dir = "network_inference/spearman"
  [[network_inference.correlation.spearman.input]]
    datatype = "otu_table"
    format = ["tsv"]
  [[network_inference.correlation.spearman.input]]
    datatype = "otu_bootstrap"
    format = ["boot"]
  [[network_inference.correlation.spearman.parameters]]
    process = "spearman"
  [[network_inference.correlation.spearman.output]]
    datatype = "interaction_table"
    format = ["tsv"]
    location = "**/*_corr.tsv"
  [[network_inference.correlation.spearman.output]]
    datatype = "interaction_bootstrap"
    format = ["boot"]
    location = "**/*_corr.boot"

## Direct

# [network_inference.direct.daa]

# [network_inference.direct.mldm]

[network_inference.direct.spieceasi]
  env = "mindpipe-spieceasi"
  root_dir = "network_inference/spieceasi"
  [[network_inference.direct.spieceasi.input]]
    datatype = "otu_table"
    format = ["tsv"]
  [[network_inference.direct.spieceasi.input]]
    datatype = "otu_bootstrap"
    format = ["boot"]
  [[network_inference.direct.spieceasi.parameters]]
    process = "spieceasi"
    method = "mb"
    ncpus = 1
    nreps = 50
    nlambda = 20
    lambda_min_ratio = 1e-2
  [[network_inference.direct.spieceasi.output]]
    datatype = "interaction_table"
    format = ["tsv"]
    location = "**/*_corr.tsv"
  [[network_inference.direct.spieceasi.output]]
    datatype = "interaction_bootstrap"
    format = ["boot"]
    location = "**/*_corr.boot"

[network_inference.direct.mldm]
  env = "mindpipe-mldm"
  root_dir = "network_inference/mldm"
  [[network_inference.direct.mldm.input]]
    datatype = "otu_table"
    format = ["tsv"]
  [[network_inference.direct.mldm.input]]
    datatype = "sample_metadata"
    format = ["tsv"]
  [[network_inference.direct.mldm.input]]
    datatype = "otu_bootstrap"
    format = ["boot"]
  [[network_inference.direct.mldm.parameters]]
    process = "mldm"
    Z_mean = 1
    max_iteration = 1500
  [[network_inference.direct.mldm.output]]
    datatype = "interaction_table"
    format = ["tsv"]
    location = "**/*_corr.tsv"
  [[network_inference.direct.mldm.output]]
    datatype = "interaction_bootstrap"
    format = ["boot"]
    location = "**/*_corr.boot"

[network_inference.direct.magma]
  env = "mindpipe-magma"
  root_dir = "network_inference/magma"
  [[network_inference.direct.magma.input]]
    datatype = "otu_table"
    format = ["tsv"]
  [[network_inference.direct.magma.input]]
    datatype = "otu_bootstrap"
    format = ["boot"]
  [[network_inference.direct.magma.parameters]]
    process = "magma"
  [[network_inference.direct.magma.output]]
    datatype = "interaction_table"
    format = ["tsv"]
    location = "**/*_corr.tsv"
  [[network_inference.direct.magma.output]]
    datatype = "interaction_bootstrap"
    format = ["boot"]
    location = "**/*_corr.boot"


## Network

[network_inference.network.make_network]
  env = "mindpipe"
  root_dir = "network_inference/make_network"
  [[network_inference.network.make_network.input]]
    datatype = "interaction_table"
    format = ["tsv"]
  [[network_inference.network.make_network.input]]
    datatype = "pvalue_table"
    format = ["tsv"]
  [[network_inference.network.make_network.input]]
    datatype = "observation_metadata"
    format = ["csv"]
  [[network_inference.network.make_network.input]]
    datatype = "children_map"
    format = ["json"]
  [[network_inference.network.make_network.input]]
    datatype = "computational_metadata"
    format = ["json"]
  [[network_inference.network.make_network.input]]
    datatype = "metadata"
    format = ["json"]
  [[network_inference.network.make_network.parameters]]
    process = "make_jsonnet"
  [[network_inference.network.make_network.output]]
    datatype = "network"
    format = ["json"]
    location = "**/*_network.json"
